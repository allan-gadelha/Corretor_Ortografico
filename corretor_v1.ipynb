{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ccdc166-3375-4d8f-8e22-a8295247cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8baefce7-fc90-4ac0-abde-9ee8a14001e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lê um arquivo de texto chamado \"Lista-de-Palavras.txt\" e armazena em um objeto do tipo DataFrame utilizando a biblioteca Pandas. \n",
    "#O parâmetro header=None indica que não há cabeçalho no arquivo e names=['Palavras'] indica que a única coluna deve ser chamada de \"Palavras\". \n",
    "#O parâmetro dtype=str especifica que o tipo de dado das colunas é string, encoding='utf-8' define a codificação do arquivo e \n",
    "#quoting=csv.QUOTE_NONE indica que não deve ser utilizada nenhuma citação para separar os campos. Por fim, na_filter=False desabilita a filtragem de valores nulos.\n",
    "df = pd.read_csv('Lista-de-Palavras.txt', header=None, names=['Palavras'], dtype=str, encoding='utf-8', quoting=csv.QUOTE_NONE, na_filter=False)\n",
    "\n",
    "#palavras_banco é uma lista que contém todas as palavras do arquivo \"Lista-de-Palavras.txt\". \n",
    "#palavras_banco_sh é uma lista que contém todas as palavras do arquivo \"Lista-de-Palavras.txt\" que não contêm o caractere '-'. Isso estava dando um problema.\n",
    "palavras_banco = df['Palavras'].tolist()\n",
    "palavras_banco_sh = [palavra for palavra in df['Palavras'] if '-' not in palavra]\n",
    "\n",
    "#Lista de palavras incorretas que serão corrigidas.\n",
    "palavras_incorretas = ['BERINJALA', 'ONOMATOPEYA', 'AXUL', 'PARALIZAR', 'ESPOJAR', 'IMPECILHO', 'UVAAZ', 'EXPECIME', 'PROESTANTISMO', 'DESECAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a3481fa-e7a2-4423-9876-ecc45a4d98a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nicialização de listas vazias que vão armazenar as correções de cada palavra incorreta.\n",
    "correcoes_lev = []\n",
    "correcoes_ang = []\n",
    "correcoes_euc = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10ff90af-f812-4d4b-9936-38042e8f0d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que calcula a distância de Levenshtein entre duas palavras.\n",
    "def distancia_levenshtein(palavra1, palavra2):\n",
    "    m, n = len(palavra1), len(palavra2)\n",
    "    d = np.zeros((m+1, n+1), dtype=float) # altera o tipo de dado para float\n",
    "    d[:, 0] = range(m+1)\n",
    "    d[0, :] = range(n+1)\n",
    "    for j in range(1, n+1):\n",
    "        for i in range(1, m+1):\n",
    "            if palavra1[i-1] == palavra2[j-1]:\n",
    "                custo = 0\n",
    "            else:\n",
    "                custo = 1\n",
    "            d[i, j] = min(d[i-1, j] + 1,          # deletar\n",
    "                          d[i, j-1] + 1,          # inserir\n",
    "                          d[i-1, j-1] + custo)    # substituir\n",
    "    return d[m, n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88bad689-1bbc-4578-b815-af94b11e0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia_euclidiana(palavra1, palavra2):\n",
    "    # Ordenando o alfabeto pela tabela ASCII\n",
    "    alphabet = sorted(list(set(palavra1 + palavra2)))\n",
    "    d = np.zeros((len(alphabet),))\n",
    "    for i, letter in enumerate(alphabet):\n",
    "        d[i] = (palavra1.count(letter) - palavra2.count(letter))**2\n",
    "    return np.sqrt(d.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67c72c9d-25c0-4e04-823e-765f68808cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia_angular(palavra1, palavra2):\n",
    "    # Ordenando o alfabeto pela tabela ASCII\n",
    "    alphabet = sorted(list(set(palavra1 + palavra2)))\n",
    "    s_vec = np.array([palavra1.count(letter) for letter in alphabet])\n",
    "    t_vec = np.array([palavra2.count(letter) for letter in alphabet])\n",
    "    s_norm = s_vec / np.linalg.norm(s_vec)\n",
    "    t_norm = t_vec / np.linalg.norm(t_vec)\n",
    "    cos_theta = np.dot(s_norm, t_norm)\n",
    "    return np.arccos(cos_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9295679-c51d-42d1-b7c4-47ec5bed3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que retorna as cinco menores distâncias e suas respectivas palavras\n",
    "def obter_cinco_menores(distancias, palavras):\n",
    "    df = pd.DataFrame({\"palavra\": palavras, \"distancia\": distancias})\n",
    "    df_ordenado = df.sort_values(by=\"distancia\")\n",
    "    cinco_menores = df_ordenado.head(5)\n",
    "    return list(zip(cinco_menores[\"palavra\"], cinco_menores[\"distancia\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4496b0fc-9c5c-40a2-b6b2-838e1df485cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrigir_palavra(palavra_incorreta):\n",
    "    distancias_lev = [distancia_levenshtein(palavra_incorreta, palavra_banco) for palavra_banco in palavras_banco_sh]\n",
    "    distancias_ang = [distancia_angular(palavra_incorreta, palavra_banco) for palavra_banco in palavras_banco_sh]\n",
    "    distancias_euc = [distancia_euclidiana(palavra_incorreta, palavra_banco) for palavra_banco in palavras_banco_sh]\n",
    "    correcoes_lev = obter_cinco_menores(distancias_lev, palavras_banco_sh)\n",
    "    correcoes_ang = obter_cinco_menores(distancias_ang, palavras_banco_sh)\n",
    "    correcoes_euc = obter_cinco_menores(distancias_euc, palavras_banco_sh)\n",
    "    return (correcoes_lev, correcoes_ang, correcoes_euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c11244d-b692-4257-afe3-7bbbff0d817e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra_incorreta</th>\n",
       "      <th>correcao_lev</th>\n",
       "      <th>correcao_ang</th>\n",
       "      <th>correcao_euc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERINJALA</td>\n",
       "      <td>BERINJELA, BENGALA, SERINGAL, SERENATA, GERMINAL</td>\n",
       "      <td>LARANJEIRA, BALNEARIO, BERINJELA, ALEIJAR, ALI...</td>\n",
       "      <td>ALEIJAR, BERINJELA, BALNEARIO, ALIENAR, BALEEIRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ONOMATOPEYA</td>\n",
       "      <td>ONOMATOPEIA, ONOMATOPEICO, FARMACOPEIA, ONOMAS...</td>\n",
       "      <td>ONOMATOPEIA, CAMPEONATO, POVOAMENTO, AMONTOAME...</td>\n",
       "      <td>ONOMATOPEIA, CAMPEONATO, POVOAMENTO, MAOMETANO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AXUL</td>\n",
       "      <td>AZUL, ATOL, SUL, UL, ATUAL</td>\n",
       "      <td>XAUAL, LUXAR, XUA, LUA, LUX</td>\n",
       "      <td>XUA, LUA, LUXAR, LUX, XAUAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PARALIZAR</td>\n",
       "      <td>PARALISAR, BANALIZAR, AVALIZAR, NASALIZAR, PAR...</td>\n",
       "      <td>PALIAR, POLARIZAR, PARALISAR, APRAZAR, ARRAIAL</td>\n",
       "      <td>ARRAIAL, PARALISAR, APRAZAR, POLARIZAR, PATRIA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESPOJAR</td>\n",
       "      <td>ESPOSAR, DESPOJAR, ESPOCAR, ESPORA, ESFOLAR</td>\n",
       "      <td>DESPOJAR, ESPORA, ARPEJO, ASPERO, SOPESAR</td>\n",
       "      <td>ESPORA, ARPEJO, DESPOJAR, ASPERO, SOBEJAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IMPECILHO</td>\n",
       "      <td>EMPECILHO, IMBECIL, IMPERIO, IMPERIOSO, IMPRECISO</td>\n",
       "      <td>HIPOGLICEMIA, EMPECILHO, HEMOFILICO, POLICHINE...</td>\n",
       "      <td>EMPECILHO, EMPIRICO, POLEMICA, MILHEIRO, MILICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UVAAZ</td>\n",
       "      <td>UVA, USADO, FUGAZ, VIA, UIVAR</td>\n",
       "      <td>VAZA, UVA, VAZAR, VAZIA, VAZAO</td>\n",
       "      <td>VAZA, SAUVA, UVA, VAZAR, VAZAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXPECIME</td>\n",
       "      <td>ESPECIME, ESPECIMEN, ESPECIE, EXPELIR, EXPERTISE</td>\n",
       "      <td>ESPECIME, PEIXE, ESPECIMEN, ESPECIE, MECE</td>\n",
       "      <td>ESPECIME, ESPECIMEN, ESPECIE, PEIXE, EPIDERME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PROESTANTISMO</td>\n",
       "      <td>PROTESTANTISMO, PROSELITISMO, ESTATISMO, DILET...</td>\n",
       "      <td>PROTESTANTISMO, MONASTERIO, MISANTROPO, OPTOME...</td>\n",
       "      <td>PROTESTANTISMO, SORTIMENTO, MISANTROPO, PRESTI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DESECAR</td>\n",
       "      <td>DEFECAR, DESEJAR, DESERCAO, DESBOCAR, PESCAR</td>\n",
       "      <td>DESCARTE, DESERCAO, ASCENDER, DESAPARECER, DES...</td>\n",
       "      <td>DESCER, DESCARTE, DESERCAO, ASCENDER, ACEDER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  palavra_incorreta                                       correcao_lev  \\\n",
       "0         BERINJALA   BERINJELA, BENGALA, SERINGAL, SERENATA, GERMINAL   \n",
       "1       ONOMATOPEYA  ONOMATOPEIA, ONOMATOPEICO, FARMACOPEIA, ONOMAS...   \n",
       "2              AXUL                         AZUL, ATOL, SUL, UL, ATUAL   \n",
       "3         PARALIZAR  PARALISAR, BANALIZAR, AVALIZAR, NASALIZAR, PAR...   \n",
       "4           ESPOJAR        ESPOSAR, DESPOJAR, ESPOCAR, ESPORA, ESFOLAR   \n",
       "5         IMPECILHO  EMPECILHO, IMBECIL, IMPERIO, IMPERIOSO, IMPRECISO   \n",
       "6             UVAAZ                      UVA, USADO, FUGAZ, VIA, UIVAR   \n",
       "7          EXPECIME   ESPECIME, ESPECIMEN, ESPECIE, EXPELIR, EXPERTISE   \n",
       "8     PROESTANTISMO  PROTESTANTISMO, PROSELITISMO, ESTATISMO, DILET...   \n",
       "9           DESECAR       DEFECAR, DESEJAR, DESERCAO, DESBOCAR, PESCAR   \n",
       "\n",
       "                                        correcao_ang  \\\n",
       "0  LARANJEIRA, BALNEARIO, BERINJELA, ALEIJAR, ALI...   \n",
       "1  ONOMATOPEIA, CAMPEONATO, POVOAMENTO, AMONTOAME...   \n",
       "2                        XAUAL, LUXAR, XUA, LUA, LUX   \n",
       "3     PALIAR, POLARIZAR, PARALISAR, APRAZAR, ARRAIAL   \n",
       "4          DESPOJAR, ESPORA, ARPEJO, ASPERO, SOPESAR   \n",
       "5  HIPOGLICEMIA, EMPECILHO, HEMOFILICO, POLICHINE...   \n",
       "6                     VAZA, UVA, VAZAR, VAZIA, VAZAO   \n",
       "7          ESPECIME, PEIXE, ESPECIMEN, ESPECIE, MECE   \n",
       "8  PROTESTANTISMO, MONASTERIO, MISANTROPO, OPTOME...   \n",
       "9  DESCARTE, DESERCAO, ASCENDER, DESAPARECER, DES...   \n",
       "\n",
       "                                        correcao_euc  \n",
       "0   ALEIJAR, BERINJELA, BALNEARIO, ALIENAR, BALEEIRA  \n",
       "1  ONOMATOPEIA, CAMPEONATO, POVOAMENTO, MAOMETANO...  \n",
       "2                        XUA, LUA, LUXAR, LUX, XAUAL  \n",
       "3  ARRAIAL, PARALISAR, APRAZAR, POLARIZAR, PATRIA...  \n",
       "4          ESPORA, ARPEJO, DESPOJAR, ASPERO, SOBEJAR  \n",
       "5    EMPECILHO, EMPIRICO, POLEMICA, MILHEIRO, MILICO  \n",
       "6                     VAZA, SAUVA, UVA, VAZAR, VAZAO  \n",
       "7      ESPECIME, ESPECIMEN, ESPECIE, PEIXE, EPIDERME  \n",
       "8  PROTESTANTISMO, SORTIMENTO, MISANTROPO, PRESTI...  \n",
       "9       DESCER, DESCARTE, DESERCAO, ASCENDER, ACEDER  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correcoes = [corrigir_palavra(palavra_incorreta) for palavra_incorreta in palavras_incorretas]\n",
    "\n",
    "# Extrai as informações necessárias da lista de correções e cria um dataframe com cada correção\n",
    "correcoes_df = pd.DataFrame(correcoes, columns=['correcao_lev', 'correcao_ang', 'correcao_euc'])\n",
    "\n",
    "# Cria uma coluna nova com as palavras incorretas\n",
    "correcoes_df['palavra_incorreta'] = palavras_incorretas\n",
    "\n",
    "# Extrai apenas a 5 primeiras palavras corrigidas de cada cálculo.\n",
    "correcoes_df['correcao_lev'] = correcoes_df['correcao_lev'].apply(lambda x: ', '.join([palavra for palavra, _ in x[:5]]))\n",
    "correcoes_df['correcao_ang'] = correcoes_df['correcao_ang'].apply(lambda x: ', '.join([palavra for palavra, _ in x[:5]]))\n",
    "correcoes_df['correcao_euc'] = correcoes_df['correcao_euc'].apply(lambda x: ', '.join([palavra for palavra, _ in x[:5]]))\n",
    "\n",
    "# Seleciona apenas as colunas desejadas\n",
    "correcoes_df = correcoes_df[['palavra_incorreta', 'correcao_lev', 'correcao_ang', 'correcao_euc']]\n",
    "\n",
    "display(correcoes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecede67-56a3-4b36-b7e7-fbab3a59885f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
